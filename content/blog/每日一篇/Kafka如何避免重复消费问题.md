---
title: Kafka如何避免重复消费问题
date: 2025-05-20
tags:
  - 面试八股文
---

首先，kafka的块上会储存offset标记，kafka消费者通过offset标记来维护已经消费的数据，消费者每消费完一批数据时会更新offset值，来避免重复消费问题。

默认情况，消费完以后会自动提交offset值避免重复消费，Kafka消费端自动提交的逻辑中默认了5秒的间隔，所以在consumer的消费过程中，如果5秒内被强行kill了或者宕机导致offset没有提交，会导致重复消费问题。

在Kafka里有一种叫Partition Balance机制，就是把多个消费区都负载均衡给consumer消费者，如果消费者在默认的五分钟内没有处理完里面的消费，就会触发ReBalance机制导致offset提交失败，在重启ReBalance后，消费端还是会从之前没有提交offset的位置开始去消费，从而导致重复消费问题，如何去解决也有很多方法：
1. 提高消费端的处理性能，避免触发Balance，例如：
	1. 比如采用异步的方法来处理消息，缩短单个信息消费的时长
	2. 调整消费处理的超时时间
	3. 减少一次性从区中获取数据的条数
2. 针对信息生产md5然后保存在MySQL或者redis里，在处理消息前先去MySQL或者redis里判断是否消费过